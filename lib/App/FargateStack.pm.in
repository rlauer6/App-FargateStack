package App::FargateStack;

########################################################################
# Copyright (C) 2025, TBC Development Group, LLC All rights reserved.  #
# This is free software and may modified or redistributed under the    #
# same terms as Perl itself.                                           #
#                                                                      #
# Repository: https://github.com/rlauer6/App-Fargate                   #
########################################################################

use strict;
use warnings;

use App::EC2;
use App::ECS;
use App::ElbV2;
use App::FargateStack::Builder::Utils qw(jmespath_mapping toCamelCase);
use App::FargateStack::Constants;
use App::Route53;
use CLI::Simple::Constants qw(:booleans :chars %LOG_LEVELS);
use CLI::Simple;
use Carp::Always;
use Carp;
use Data::Dumper;
use Date::Parse qw(str2time);
use English qw(no_match_vars);
use File::Basename qw(basename);
use List::Util qw(none);
use Log::Log4perl;
use Pod::Usage;
use Scalar::Util qw(reftype);
use Text::ASCIITable::EasyTable;
use YAML qw(LoadFile);

use Role::Tiny::With;

with 'App::Benchmark';
with 'App::FargateStack::Builder';
with 'App::FargateStack::Builder::IAM';
with 'App::FargateStack::Builder::Certificate';
with 'App::FargateStack::Builder::Events';
with 'App::FargateStack::Builder::EFS';
with 'App::FargateStack::Builder::HTTPService';
with 'App::FargateStack::Builder::Cluster';
with 'App::FargateStack::Builder::LogGroup';
with 'App::FargateStack::Builder::SecurityGroup';
with 'App::FargateStack::Builder::Secrets';
with 'App::FargateStack::Builder::Service';
with 'App::FargateStack::Builder::S3Bucket';
with 'App::FargateStack::Builder::SQSQueue';
with 'App::FargateStack::Builder::TaskDefinition';
with 'App::FargateStack::Builder::Utils';

our $VERSION = '@PACKAGE_VERSION@';

use parent qw(CLI::Simple);

__PACKAGE__->use_log4perl( config => $LOG4PERL_CONF );

caller or __PACKAGE__->main;

########################################################################
sub init {
########################################################################
  my ($self) = @_;

  my $command = $self->command;

  return
    if $command =~ /version|help/xsm;

  my $dryrun = $self->get_dryrun;
  $self->set_dryrun( $dryrun ? '(dryrun)' : $EMPTY );

  log_die( $self, 'ERROR: when applying changes --no-update is not allowed' )
    if !$dryrun && !$self->get_update;

  my $config = $self->_init_config;

  $self->_init_defaults($config);

  $self->_init_account;

  my $ec2 = $self->_init_ec2( $config->{vpc_id}, %{ $self->get_global_options } );

  $self->set_ecs(
    App::ECS->new(
      ec2 => $ec2,
      %{ $self->get_global_options },
    )
  );

  my $elb = App::ElbV2->new(
    vpc_id => $config->{vpc_id},
    ec2    => $ec2,
    %{ $self->get_global_options },
  );

  $self->set_elb($elb);

  # this will determine if we have an http service defined, configure
  # the ALB if it is not set explicitly and check on required parameters
  $self->_init_tasks();

  $self->_init_route53();

  $self->get_logger->trace( sub { return Dumper( [ config => $config ] ); } );

  $self->show_config;

  # only install die handler for apply - this makes sure we record any
  # provisioned resources
  if ( $self->command eq 'apply' ) {
    $SIG{__DIE__} = sub {
      my $msg = shift;

      return if $EXCEPTIONS_BEING_CAUGHT;  # eval

      # if config exists...we have removed last_updated and id
      if ( $config && $config->{config_name} ) {
        warn sprintf "Unclean shutdown - writing config file to [%s]\n", $config->{config_name};
        eval { YAML::DumpFile( $config->{config_name}, $config ); }
      }

      die $msg;
    };
  }

  return $TRUE;
}

########################################################################
sub show_config {
########################################################################
  my ($self) = @_;

  my $config  = $self->get_config;
  my $subnets = $self->get_subnets;

  $self->log_info( 'init:           account: [%s]', $self->get_account );
  $self->log_info( 'init:           profile: [%s]', $self->get_profile );
  $self->log_info( 'init:    profile source: [%s]', $self->get_profile_source );
  $self->log_info( 'init:            region: [%s]', $self->get_region );
  $self->section_break;

  $self->log_info( 'init:   route53 profile: [%s]', $config->{route53}->{profile} // q{-} );
  $self->log_info( 'init:   route53 zone_id: [%s]', $config->{route53}->{zone_id} // q{-} );
  $self->section_break;

  $self->log_info( 'init:          app name: [%s]', $config->{app}->{name} );
  $self->log_info( 'init:       app version: [%s]', $config->{app}->{version} // q{-} );
  $self->log_info( 'init:     https service: [%s]', $self->get_http           // q{-} );
  $self->log_info( 'init:  scheduled events: [%s]', $self->has_events ? 'yes' : 'no' );
  $self->section_break;

  $self->log_info( 'init:    subnets in VPC: [%s]', $config->{vpc_id} );
  $self->log_info( '                 public: [%s]', join q{,}, @{ $subnets->{private} || [] } );
  $self->log_info( '                private: [%s]', join q{,}, @{ $subnets->{public}  || [] } );
  $self->section_break;

  $self->log_info( 'init:            config: [%s]', $self->get_config_name );
  $self->log_info( 'init:         log level: [%s]', $self->get_log_level // 'info' );
  $self->log_info( 'init:             cache: [%s]', $self->get_cache ? 'enabled' : 'disabled' );
  $self->log_warn( 'init:     update config: [%s]', $self->get_update ? 'yes' : 'no' );
  $self->log_warn( 'init:            dryrun: [%s]', $self->get_dryrun ? 'yes' : 'no' );

  return;
}

########################################################################
sub _init_tasks {
########################################################################
  my ($self) = @_;

  my $config = $self->get_config;

  my $tasks = $config->{tasks};

  log_die( $self, "ERROR: no tasks defined in config\n" )
    if !$tasks;

  # see if we have an http service
  my ( $http_service, $error )
    = grep { $tasks->{$_}->{type} && $tasks->{$_}->{type} =~ /^http/xsm } keys %{$tasks};

  log_die( $self, 'ERROR: only one http service is permitted' )
    if $error;

  $self->set_http($http_service);

  if ($http_service) {
    $self->configure_alb();

    log_die( $self, "ERROR: when provisioning an http task, domain is required\n" )
      if !$config->{domain};

  }

  my @images = map { $tasks->{$_}->{image} // () } keys %{$tasks};

  log_die(
    $self,
    "ERROR: every task must have an image\n%s",
    Dumper(
      [ images => \@images,
        tasks  => $tasks
      ]
    )
  ) if @images != scalar keys %{$tasks};

  return
    if $self->get_cache;

  require App::ECR;

  my $ecr = App::ECR->new( $self->get_global_options );

  $ecr->validate_images(@images);

  return;
}

########################################################################
sub _init_account {
########################################################################
  my ($self) = @_;

  my $config = $self->get_config;

  if ( $config->{account} && $self->get_cache ) {
    $self->set_account( $config->{account} );
    return;
  }

  require App::STS;

  my $sts = App::STS->new( profile => $self->get_profile, %{ $self->get_global_options } );

  $self->set_sts($sts);

  $self->log_info('init: determining AWS account value...');

  my $result = $sts->get_caller_identity;

  log_die( $self, "ERROR: could not determine account\n%s", $sts->get_error )
    if !$result;

  $config->{account} = $result->{Account};
  $self->log_info( 'init: AWS account: [%s]...', $config->{account} );

  $self->set_account( $config->{account} );

  return;
}

########################################################################
sub _init_defaults {
########################################################################
  my ( $self, $config ) = @_;

  my $last_updated = delete $config->{last_updated};
  delete $config->{id};

  $config->{region} //= $self->get_region // $ENV{AWS_DEFAULT_REGION} // 'us-east-1';
  $self->set_region( $config->{region} );  # let's make sure we can use get_region()

  my $profile        = $self->get_profile;
  my $profile_source = 'command line';

  if ( !$profile && $config->{profile} ) {
    $profile        = $config->{profile};
    $profile_source = 'config';
  }
  elsif ( !$profile && $ENV{AWS_PROFILE} ) {
    $profile        = $ENV{AWS_PROFILE};
    $profile_source = 'environment';
  }

  if ( !$profile ) {
    $profile        = 'default';
    $profile_source = 'default';
  }

  $self->set_profile($profile);
  $config->{profile} = $profile;

  $self->set_profile_source($profile_source);

  $config->{default_log_group} //= sprintf '/ecs/' . $config->{app}->{name};

  my %global_options = (
    profile   => $self->get_profile,
    region    => $self->get_region,
    logger    => $self->get_logger,
    log_level => $self->get_log_level,
    unlink    => $self->get_unlink,
  );

  $self->set_global_options( \%global_options );

  my $cache = $self->get_cache;
  $self->set_cache( $cache && $last_updated ? '(cached)' : $EMPTY );

  return;
}

########################################################################
sub _init_route53 {
########################################################################
  my ($self) = @_;

  my $command = $self->command;

  my @route53_commands = qw(apply plan list-hosted-zones);

  return
    if none { $command eq $_ } @route53_commands;

  return
    if !$self->get_http && $command =~ /apply|plan/xsm;

  my $config = $self->get_config;

  $self->log_trace( sub { return Dumper( [ alb => $config->{alb}, $self->get_http ] ) } );

  my $alb_type = $config->{alb}->{type};

  my ( $route53_config, $domain ) = @{$config}{qw(route53 domain)};

  if ( !$route53_config ) {
    $route53_config = {};
    $config->{route53} = $route53_config;
  }

  $route53_config->{profile} //= $self->get_route53_profile // $self->get_profile;

  my ( $zone_id, $profile ) = @{$route53_config}{qw(zone_id profile)};

  my $route53 = App::Route53->new(
    hosted_zone_id => $zone_id,
    elb            => $self->get_elb,
    %{ $self->get_global_options },
    profile => $profile,
  );

  $self->set_route53($route53);

  if ( !$zone_id ) {
    my $zone_type = $self->is_https ? 'public' : 'private';

    $self->log_warn( 'init: zone_id is required when creating a task of type: [%s]',
      $self->is_https ? 'https' : 'http' );

    $self->log_warn( 'init: ...attempting to find a [%s] hosted zone', $zone_type );

    my $hosted_zone = $route53->find_hosted_zone( $domain, $zone_type );
    $self->benchmark('route53');

    log_die( $self, 'init: ERROR: no hosted zone of type [%s] found in this account for domain: [%s]',
      $zone_type, $domain )
      if !$hosted_zone || !@{$hosted_zone};

    $zone_id = basename( $hosted_zone->[0]->{Id} );
    $route53_config->{zone_id} = $zone_id;

    return;
  }

  return
    if $self->get_cache;

  $self->log_warn( 'init: validating hosted zone id: [%s]', $zone_id );

  my $zone = eval {
    return $route53->validate_hosted_zone(
      zone_id  => $zone_id,
      domain   => $domain,
      alb_type => $alb_type,
    );
  };

  my $err = $EVAL_ERROR;

  return
    if $zone && !$err;

  # output a helpful table of hosted zones for this domain
  $self->log_warn( "\n" . $self->display_hosted_zones($domain) );

  ($err) = split /\n/, $err;

  log_die( $self, $err );

  return;
}

########################################################################
sub cmd_logs {
########################################################################
  my ($self) = @_;

  my $config = $self->get_config;

  my ( $task_name, $start, $end ) = $self->get_args;

  $self->check_task($task_name);

  my $tasks = $config->{tasks};

  my $task = $tasks->{$task_name};

  my ( $start_time, $end_time ) = normalize_time_range( $start, $end );

  require App::Logs;

  my $logs = App::Logs->new( $self->get_global_options );

  my @elems = qw(log_stream_name first_event_timestamp);

  my $query = jmespath_mapping( 'logStreams[0]', scalar toCamelCase( \@elems ) );

  my $log_group = $task->{log_group}->{name};

  my $stream = $logs->command(
    'describe-log-streams' => [
      '--log-group-name' => $log_group,
      '--order-by'       => 'LastEventTime',
      '--descending',
      '--query' => $query,
    ]
  );

  croak sprintf "ERROR: could not describe log group [%s]\n%s\n", $log_group, $logs->get_error
    if !$stream;

  croak sprintf "no log streams found for log group: [%s]\n", $log_group
    if !ref $stream;

  my %options = (
    '--log-group-name'  => $log_group,
    '--log-stream-name' => $stream->{log_stream_name},
  );

  $start_time //= $stream->{last_event_timestamp};

  my $events = $logs->command(
    'get-log-events' => [
      %options,
      $start_time ? ( '--start-time' => $start_time ) : (),
      $end_time   ? ( '--end-time'   => $end_time )   : (),
    ]
  );

  EVENT:
  while ( $events && @{ $events->{events} } ) {
    my @log_events = @{ $events->{events} };

    foreach my $e (@log_events) {
      my ( $timestamp, $message ) = @{$e}{qw(timestamp message)};
      $timestamp = $self->get_log_time ? scalar localtime $timestamp / 1000 : $EMPTY;

      print {*STDOUT} sprintf "%s - %s\n", $timestamp, $message;
    }

    my $token = $events->{nextForwardToken};

    while ($TRUE) {
      $events = $logs->command( 'get-log-events', [ %options, '--next-token' => $token ] );

      if ( !$events || !@{ $events->{events} } ) {
        last EVENT
          if !$self->get_log_wait;

        sleep $DEFAULT_LOG_POLL_TIME;
      }
      else {
        last;
      }
    }
  }

  return $SUCCESS;
}

########################################################################
sub normalize_time_range {
########################################################################
  my ( $start, $end ) = @_;

  return
    if !$start;

  my $now = time;

  my $start_epoch = _to_epoch( $start, $now );
  my $end_epoch   = defined $end ? _to_epoch( $end, $now ) : undef;

  croak 'start is in the future' if $start_epoch > $now;
  croak 'end is in the future'   if defined $end_epoch && $end_epoch > $now;
  croak 'start > end'            if defined $end_epoch && $start_epoch > $end_epoch;

  return ( $start_epoch * 1000, defined $end_epoch ? $end_epoch * 1000 : undef );
}

########################################################################
sub _to_epoch {
########################################################################
  my ( $value, $now ) = @_;

  # Duration syntax (e.g. 5d, 30m, 2h)
  if ( $value =~ /^(\d+)([dmh])$/xsmi ) {
    my ( $n, $unit ) = ( $1, lc $2 );
    croak 'duration cannot be zero' if $n == 0;

    my %span = (
      d => $SEC_PER_DAY,
      h => $SEC_PER_HOUR,
      m => $SEC_PER_MIN,
    );

    return $now - $n * $span{$unit};
  }

  # Date string ‑ let Date::Parse do the heavy lifting
  my $epoch = str2time($value);

  croak "unrecognized date format: [$value]"
    if !defined $epoch;

  return $epoch;
}

########################################################################
sub cmd_list_zones {
########################################################################
  my ($self) = @_;

  my ($domain) = $self->get_args;

  croak sprintf "usage: %s list-zones domain\n", $ENV{SCRIPT_NAME}
    if !$domain;

  print {*STDOUT} $self->display_hosted_zones($domain);

  return $SUCCESS;
}

########################################################################
sub display_hosted_zones {
########################################################################
  my ( $self, $domain ) = @_;

  if ( !$self->get_route53 ) {
    $self->set_route53( App::Route53->new( $self->get_global_options ) );
  }

  my $hosted_zones = $self->get_route53->list_hosted_zones;

  return
    if !$hosted_zones || !@{ $hosted_zones->{HostedZones} };

  my @zones = @{ $hosted_zones->{HostedZones} };

  my @data;

  foreach my $zone (@zones) {
    my $name = $zone->{Name};
    $name =~ s/[.]$//xsm;

    next if $domain !~ /$name/xsm;

    my ($zone_id) = ( split /\//xsm, $zone->{Id} )[-1];

    push @data, { 'Zone Id' => $zone_id, Name => $zone->{Name} };
  }

  my $title = sprintf 'Hosted Zones (%s)', $domain;

  my $table = easy_table(
    data          => [@data],
    table_options => { headingText => $title },
    columns       => [ 'Zone Id', 'Name' ],
  );

  return $table;
}

########################################################################
sub _init_ec2 {
########################################################################
  my ($self) = @_;

  my $config = $self->get_config;

  my $subnets = $config->{subnets};

  my $ec2 = App::EC2->new(
    vpc_id => $config->{vpc_id},
    ( $self->get_cache && $subnets ) ? ( subnets => $subnets ) : (),
    %{ $self->get_global_options },
  );

  $subnets = $ec2->get_subnets;

  $self->get_logger->trace( sub { return Dumper( [ subnets => $subnets ] ) } );

  $self->set_subnets($subnets);

  $self->set_ec2($ec2);

  $config->{vpc_id} = $ec2->get_vpc_id;

  # if we find subnets in the config...always validate in case they
  # got changed...
  if ( $subnets && !$self->get_cache ) {
    $ec2->validate_subnets($subnets);  # this will croak if any are invalid
  }
  else {
    my $subnets = $ec2->get_subnets;
    $self->set_subnets($subnets);
    $config->{subnets} = $subnets;
  }

  $self->get_logger->trace( sub { return Dumper( [ subnets => $subnets ] ) } );

  return $ec2;
}

########################################################################
sub cmd_service_status {
########################################################################
  my ($self) = @_;

  my ($service_name) = $self->get_args;

  require Text::Wrap;
  Text::Wrap->import('wrap');

  {
    ## no critic
    no warnings 'once';
    $Text::Wrap::columns = 100;
  }

  my @elems = qw(running_count desired_count status pending events);

  my $query = jmespath_mapping 'services[0]' => \@elems;

  my $result = $self->get_ecs->describe_services(
    cluster_name => $self->get_config->{cluster}->{name},
    service_name => $service_name,
    query        => $query,
  );

  log_die( $self, "ERROR: could not describe service [%s]\n%s", $service_name, $self->get_ecs->get_error )
    if !$result;

  croak sprintf "ERROR: no service named: [%s] is currently running\n", $service_name
    if !ref $result;

  my $title = sprintf 'Service: %s Status:[%s] Running: [%s] Pending: [%s] Desired: [%s]', $service_name,
    @{$result}{qw(status running_count pending desired_count)};

  my @data
    = map { { 'Time' => $_->{createdAt}, Event => wrap( q{}, q{}, $_->{message} ) } } @{ $result->{events} };

  print {*STDOUT} easy_table(
    table_options => { headingText => $title },
    data          => \@data,
    columns       => [qw(Time Event)],
  );

  return $SUCCESS;
}

########################################################################
sub _init_config {
########################################################################
  my ($self) = @_;

  my $config_file = $self->get_config // $ENV{FARGATE_STACK_CONFIG} // 'fargate-stack.yml';

  croak sprintf "ERROR: %s not found or is unreadable\n", $config_file
    if !-s $config_file || !-r $config_file;

  $self->set_config_name($config_file);

  $self->section_break;

  $self->log_info( '%s %s (c) Copyright 2025 TBC Development Group, LLC', ref $self, $VERSION );
  $self->section_break;

  my $config = LoadFile($config_file);

  $config->{config_name} = $config_file;

  $self->set_config($config);

  return $config;
}

########################################################################
sub cmd_run_task {
########################################################################
  my ($self) = @_;

  my $config = $self->get_config;

  my ($task_name) = $self->get_args;

  log_die( $self, "usage: %s run-task task-name\n", $ENV{SCRIPT_NAME} )
    if !$task_name;

  my $task = $config->{tasks}->{$task_name};

  log_die( $self, "ERROR: no such task [%s] defined in config\n", $task_name )
    if !$task;

  my @subnets = @{ $self->get_subnets->{private} // [] };

  if ( !@subnets ) {
    $self->log_warn('run-task: using public subnets is not recommended...');
    @subnets = @{ $self->get_subnets->{public} // [] };
  }

  my $network_configuration = {
    awsvpcConfiguration => {
      subnets        => [ @subnets[ 0, 1 ] ],
      securityGroups => [ $config->{security_groups}->{fargate}->{group_id} ],
      assignPublicIp => 'DISABLED',
    }
  };

  my $cluster_name = $config->{cluster}->{name};

  $self->log_warn( 'run-task: launching [%s] in cluster [%s]', $task_name, $cluster_name );

  my $result = $self->get_ecs->run_task(
    cluster               => $cluster_name,
    task_definition       => $task_name,
    network_configuration => $network_configuration,
  );

  log_die( $self, "ERROR: could not run task [%s]\n%s\n", $task_name, $self->get_ecs->get_error )
    if !$result;

  my @failures = @{ $result->{failures} };

  log_die( $self, 'ERROR: task failed to launch: %s', Dumper( \@failures ) )
    if @failures;

  my ($tasks) = @{ $result->{tasks} };

  my $task_arn = $tasks->{taskArn};

  my $should_wait = $self->get_wait ? '(waiting)' : $EMPTY;

  $self->log_warn( 'run-task: task [%s] launched. ARN: [%s]...%s', $task_name, $task_arn, $should_wait );

  my $poll_limit = $self->get_task_timeout / $DEFAULT_ECS_POLL_TIME;

  if ($should_wait) {
    my $poll_count = 0;

    while ( $poll_count++ < $poll_limit ) {

      my ( $status, $stopped_reason, $exit_code ) = $self->get_task_status( $cluster_name, $task_arn );

      $self->log_warn( 'run-task: task [%s] status: [%s], exit code:[%s], reason: [%s]',
        $task_name, map { $_ // q{-} } ( $status, $exit_code, $stopped_reason ) );

      last if $status eq 'STOPPED';

      sleep $DEFAULT_ECS_POLL_TIME;
    }

    my $log_group = $config->{tasks}->{$task_name}->{log_group}->{name};

    # by convention our log groups are named after our app
    my $log_stream = sprintf '%s/%s/%s', $config->{app}->{name}, $task_name, ( split /\//xsm, $task_arn )[-1];

    require App::Logs;

    my $logs = App::Logs->new(
      %{ $self->get_global_options },
      log_group_name  => $log_group,
      log_stream_name => $log_stream
    );

    my $events = $logs->get_log_events();

    log_die( $self, "run-task: unable to get logs from log group: [%s], stream: [%s]\n%s",
      $log_group, $log_stream, $logs->get_error )
      if !$events;

    while ( $events && @{ $events->{events} } ) {

      foreach my $e ( @{ $events->{events} } ) {

        my ( $timestamp, $message ) = @{$e}{qw(timestamp message)};
        $timestamp = scalar localtime $timestamp / 1000;

        print {*STDOUT} sprintf "%s - %s\n", $timestamp, $message;
      }

      $events = $logs->get_next_log_events( $events->{nextForwardToken} );
    }
  }

  return $SUCCESS;
}

########################################################################
sub get_task_status {
########################################################################
  my ( $self, $cluster_name, $task_arn ) = @_;

  my @elems = qw(last_status stopped_reason containers);

  my $query = jmespath_mapping 'tasks[0]' => \@elems;

  my $result = $self->get_ecs->describe_tasks( $cluster_name, $task_arn, $query );

  croak sprintf "ERROR: unable to describe task: [%s]\n%s", $task_arn, $self->get_ecs->get_error
    if !$result;

  my ( $status, $stopped_reason, $containers ) = @{$result}{@elems};

  return ( $status, $stopped_reason, $containers->[0]->{exitCode} );
}

########################################################################
sub cmd_create_service {
########################################################################
  my ($self) = @_;

  my ($task_name) = $self->get_args;

  my $config = $self->get_config;

  log_die( $self, "usage: $ENV{SCRIPT_NAME} create-service task-name\n" )
    if !$task_name;

  log_die( $self, "no such task defined in config [%s]\n", $task_name )
    if !$config->{tasks}->{$task_name};

  return $self->build_service($task_name);
}

########################################################################
sub check_task {
########################################################################
  my ( $self, $task_name, $warn ) = @_;

  my $level = $warn ? 'warn' : 'die';

  my $config = $self->get_config;

  return $TRUE
    if $task_name && $config->{tasks}->{$task_name};

  log_die( $self, 'ERROR:  no such task [%s] defined in config', $task_name )
    if $level eq 'die';

  $self->get_logger->warn( 'WARNING: no such task [%s] defined in config...trying anyway  ¯\_(ツ)_/¯',
    $task_name );

  return;
}

########################################################################
sub cmd_delete_service {
########################################################################
  my ($self) = @_;

  my ($task_name) = $self->get_args;

  croak "usage: %s delete-service task-name\n", $ENV{SCRIPT_NAME}
    if !$task_name;

  my $config = $self->get_config;

  $self->check_task( $task_name, 'warn' );

  my $ecs = $self->get_ecs;

  my $result = $ecs->delete_service( $config->{cluster}->{name}, $task_name );

  log_die( $self, "ERROR: could not stop service %s\n%s", $task_name, $ecs->get_error )
    if $ecs->get_error;

  return $SUCCESS;
}

########################################################################
sub _update_task_count {
########################################################################
  my ( $self, $task_name, $desired_count ) = @_;

  my $config = $self->get_config;

  my $ecs = $self->get_ecs;

  my $cluster_name = $config->{cluster}->{name};

  my $result = $ecs->command(
    'update-service' => [
      '--cluster'       => $cluster_name,
      '--service'       => $task_name,
      '--desired-count' => $desired_count,
    ]
  );

  log_die( $self, "ERROR: could not update service: [%s]\n%s", $task_name, $ecs->get_error )
    if !$result;

  return $result;
}

########################################################################
sub cmd_update_service {
########################################################################
  my ($self) = @_;

  my ( $task_name, $count ) = $self->get_args;

  if ( $self->command eq 'start-service' ) {
    $count ||= 1;
  }
  else {
    $count = 0;
  }

  $self->check_task( $task_name, 'warn' );

  if ( !$task_name ) {
    if ( $count == 0 ) {
      croak sprintf "usage: %s -c config-name stop-service task-name\n", $ENV{SCRIPT_NAME};
    }

    croak sprintf "usage: %s -c config-name start-service task-name [count]\n", $ENV{SCRIPT_NAME};
  }

  my $result = $self->_update_task_count( $task_name, $count );

  sleep 2;  # wait a few seconds for status to be updated

  return $self->cmd_service_status;
}

########################################################################
sub cmd_register {
########################################################################
  my ($self) = @_;

  my $config = $self->get_config;

  my ($task_name) = $self->get_args;

  my $dryrun = $self->get_dryrun;

  my $action = $self->get_skip_register ? 'update-target' : 'register';

  log_die( $self, 'usage: %s %s task-name', $action, $ENV{SCRIPT_NAME} )
    if !$task_name;

  my $ecs = $self->get_ecs;

  my $task_definition_file = sprintf 'taskdef-%s.json', $task_name;

  $self->check_task($task_name);

  log_die( $self, "ERROR: no task definition file found for %s\n", $task_name )
    if !-s $task_definition_file;

  my $tasks = $config->{tasks};

  my $task_definition_arn;

  if ( !$self->get_skip_register ) {
    $self->log_warn( 'register: registering [%s]...%s', $task_name, $dryrun );

    if ( !$dryrun ) {
      my $task_definition = $ecs->register_task_definition($task_definition_file);

      log_die( $self, 'register: could not register [%s]', $task_definition_file )
        if !$task_definition;

      $self->log_trace( sub { return Dumper( [ task_definition => $task_definition ] ) } );

      $task_definition_arn = $task_definition_arn->{taskDefinition}->{taskDefinitionArn};
      $self->log_warn( 'register: registered...[%s]', $task_definition_arn );
      $tasks->{$task_name}->{arn} = $task_definition_arn;
      $self->update_config;  # record new task definition arn
    }
  }

  ## - events -
  if ( $tasks->{$task_name}->{type} eq 'task' ) {
    my $event = App::Events->new( $self->get_global_options );

    my $rule_name = sprintf '%s-schedule', $task_name;

    my $target = $event->list_targets_by_rule( $rule_name, 'Targets' );

    if ( $target && @{$target} ) {

      # we only need to update the config if we skipped
      # registration...this is to allow for updating an event target
      # with a new task definition manually
      if ( !$dryrun && $self->get_skip_register ) {
        $config->{tasks}->{$task_name}->{arn} = $task_definition_arn;
        $self->update_config;
      }

      $self->create_event_target($task_name);
    }
  }

  return $SUCCESS;
}

########################################################################
sub cmd_explain {
########################################################################
  my ($self) = @_;

  my $config = $self->get_config;

  return $SUCCESS;
}

########################################################################
sub cmd_version {
########################################################################

  my $version_stmt = <<'END_OF_TEXT';
%s %s
Copyright 2025 (c) TBC Development Group, LLC.

License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
END_OF_TEXT

  my $pgm = $ENV{SCRIPT_NAME} // $PROGRAM_NAME;

  print {*STDOUT} sprintf $version_stmt, $pgm, $VERSION;

  return $SUCCESS;
}

########################################################################
sub help {
########################################################################
  my ($self) = @_;

  my $subject = lc join $SPACE, @ARGV;
  $subject =~ s/\s+$//xsm;

  my $section = $HELP_SUBJECTS{$subject} // $EMPTY;

  if ( $subject && !$section ) {
    my @possible_subjects = grep {/$subject/xsmi} keys %HELP_SUBJECTS;

    if ( @possible_subjects == 1 ) {
      $section = $HELP_SUBJECTS{ $possible_subjects[0] };
    }
    elsif (@possible_subjects) {
      print {*STDERR} sprintf "'%s' was not found in the help index.\n\nPossible matches:\n\t* %s\n", $subject,
        join "\n\t* ",
        @possible_subjects;
      exit 1;
    }
  }

  if ( $section && ref $section ) {
    $section = $section->[0];
  }
  elsif ($section) {  # a help subject alias
    my $reference = $HELP_SUBJECTS{$section};
    $section = $reference->[0];
  }

  if ( $subject && !$section ) {
    if ( $subject ne 'list' ) {
      print {*STDERR} sprintf "'%s' is not a valid subject\n", $subject;
    }

    my @data;

    foreach my $keyword ( sort keys %HELP_SUBJECTS ) {
      my $description = $HELP_SUBJECTS{$keyword};
      if ( ref $description ) {
        $description = $description->[1];
      }
      push @data, { Keyword => $keyword, Description => $description };
    }

    my $table = easy_table(
      columns       => [qw(Keyword Description)],
      data          => \@data,
      table_options => { headingText => 'Help Subjects' },
    );

    print {*STDOUT} $table;

    return $SUCCESS;
  }

  eval {
    require IO::Pager;
    IO::Pager::open( *STDOUT, '|-:utf8', 'Unbuffered' );
  };

  return pod2usage(
    -exitval => 1,
    -verbose => 99,
    $section ? ( -sections => uc $section // 'USAGE' ) : ()
  );
}

########################################################################
sub init_logger {
########################################################################
  my ($self) = @_;

  #  my $log4perl_conf = $LOG4PERL_CONF;

  my $log4perl_conf = $self->get_log4perl_conf;

  if ( !$self->get_color ) {
    $log4perl_conf =~ s/\ColoredLevels//xsm;
  }

  $self->set_log4perl_conf($log4perl_conf);
  return $self->SUPER::init_logger;

  #  Log::Log4perl->init( \$log4perl_conf );
  #
  #  $self->set_logger( Log::Log4perl->get_logger );
  #
  #  my $level = $self->get_log_level;
  #
  #  $self->get_logger->level( $LOG_LEVELS{ $level // 'info' } );
  #
  #  return;
}

########################################################################
sub cmd_plan {
########################################################################
  my ( $self, @args ) = @_;

  $self->set_dryrun('(dryrun)');

  return $self->build(@args);
}

########################################################################
sub cmd_apply {
########################################################################
  my ( $self, @args ) = @_;

  $self->set_dryrun($EMPTY);

  return $self->build(@args);
}

########################################################################
sub cmd_update_target {
########################################################################
  my ( $self, @args ) = @_;

  $self->set_skip_register($TRUE);

  return $self->cmd_register(@args);
}

########################################################################
sub cmd_stop_task {
########################################################################
  my ( $self, @args ) = @_;

  my $config = $self->get_config;

  my ($task_id) = $self->get_args;

  my $ecs = $self->get_ecs;

  croak sprintf "usage: %s stop-task -c config.yml task-id|task-arn\n", $ENV{SCRIPT_NAME}
    if none { length $task_id == $_ } ( 32, 36 );

  my $result = $ecs->stop_task( $config->{cluster}->{name}, $task_id );

  log_die( $self, "ERROR: could not stop task: [%s]\n%s", $task_id, $ecs->get_error )
    if !$result;

  return $SUCCESS;
}

########################################################################
sub cmd_list_tasks {
########################################################################
  my ( $self, @args ) = @_;

  my $config = $self->get_config;

  my $cluster_name = $config->{cluster}->{name};

  my $ecs = $self->get_ecs;

  my $result = $ecs->list_tasks( $cluster_name, 'taskArns' );

  croak sprintf "ERROR: could not list tasks for cluster: [%s]\n%s", $cluster_name, $ecs->get_error
    if !$result;

  if ( !@{$result} ) {
    print {*STDERR} sprintf "No tasks currently running in cluster: [%s]\n", $cluster_name;

    return $SUCCESS;
  }

  my @task_ids  = map { basename $_ } @{$result};
  my $task_list = join q{ }, @task_ids;

  my @elems = qw(status task_definition_arn last_status started_at memory cpu attachments task_arn);

  my $query = jmespath_mapping 'task[]' => \@elems;

  $result = $ecs->describe_tasks( $cluster_name, $task_list, $query );

  croak sprintf "ERROR: could not list describe tasks: [%s]\n%s", $cluster_name, $ecs->get_error
    if !$result;

  my $title = sprintf 'Tasks (cluster: %s)', $cluster_name;

  my @data;

  foreach ( @{$result} ) {
    my ( $status, $last_status, $start_time, $memory, $cpu, $arn )
      = @{$_}{qw(status last_status started_at memory cpu task_arn)};
    my $task_name = basename( $_->{task_definition_arn} );
    $task_name =~ s/:\d+$//;

    push @data,
      {
      'Start Time'   => $start_time,
      Status         => $status // $last_status,
      Memory         => $memory,
      CPU            => $cpu,
      'Task Id'      => basename($arn),
      'Task Name'    => $task_name,
      'Elapsed Time' => elapsed_time($start_time),
      };
  }

  print {*STDOUT} easy_table(
    table_options => { headingText => $title },
    data          => \@data,
    columns       => [ 'Task Name', 'Task Id', 'Status', 'Memory', 'CPU', 'Start Time', 'Elapsed Time' ],
  );

  return $SUCCESS;
}

########################################################################
sub cmd_ {
########################################################################
  my ( $self, @args ) = @_;

  return $SUCCESS;
}

########################################################################
sub cmd_update_policy {
########################################################################
  my ( $self, @args ) = @_;

  $self->set_cache($FALSE);

  return $self->build(@args);
}

########################################################################
sub main {
########################################################################

  my @extra_options = qw(
    account
    alb
    config_name
    ec2
    ecs
    efs
    elb
    events
    existing_resources
    http
    iam
    global_options
    logs
    log_groups
    logger
    profile_source
    required_resources
    route53
    sts
    secrets
    subnets
    taskdef_status
  );

  my @option_specs = qw(
    help|h
    config|c=s
    color!
    create-alb|C
    dryrun|d
    profile|p=s
    log-level=s
    log-time!
    log-wait!
    region|r=s
    route53-profile|R=s
    skip-register|s
    task-timeout|t
    update|u!
    unlink|U!
    cache!
    version|v
    wait|w!
  );

  my %default_options = (
    'update'       => $TRUE,
    wait           => $TRUE,
    unlink         => $TRUE,
    color          => $TRUE,
    cache          => $TRUE,
    'log-time'     => $TRUE,
    'log-wait'     => $TRUE,
    'task-timeout' => $DEFAULT_ECS_POLL_LIMIT,
  );

  my %commands = (
    'create-service' => [ \&cmd_create_service, 'error' ],
    'delete-service' => [ \&cmd_delete_service, 'error' ],
    'list-tasks'     => [ \&cmd_list_tasks,     'error' ],
    'list-zones'     => [ \&cmd_list_zones,     'error' ],
    'run-task'       => \&cmd_run_task,
    'start-service'  => [ \&cmd_update_service, 'error' ],
    'stop-service'   => [ \&cmd_update_service, 'error' ],
    'stop-task'      => [ \&cmd_stop_task,      'error' ],
    'update-policy'  => \&cmd_update_policy,
    'update-target'  => \&cmd_update_target,
    apply            => \&cmd_apply,
    default          => [ \&cmd_explain, 'error' ],
    help             => [ \&help,        'error' ],
    logs             => [ \&cmd_logs,    'error' ],
    plan             => \&cmd_plan,
    register         => \&cmd_register,
    start            => \&cmd_start_service,
    status           => [ \&cmd_service_status, 'error' ],
    stop             => \&cmd_stop_service,
    version          => [ \&cmd_version, 'error' ],
  );

  my $fargate_stack = App::FargateStack->new(
    commands        => \%commands,
    default_options => \%default_options,
    extra_options   => \@extra_options,
    option_specs    => \@option_specs,
  );

  $fargate_stack->run();

  return 0;
}

1;

__END__

=pod

=head1 NAME

App::FargateStack

=head1 SYNOPSIS

 # Dry-run and analyze the configuration
 app-FargateStack plan -c my-stack.yml

 # Provision the full stack
 app-FargateStack apply -c my-stack.yml

=head1 DESCRIPTION

I<NOTE: This is a work in progress. The documentation may be
incomplete. Expect some features to change and more features to be
added. See the L</ROADMAP> section for upcoming features.>

B<App::FargateStack> is a lightweight deployment framework for Amazon
ECS on Fargate.  It enables you to define and launch containerized
services with minimal AWS-specific knowledge and virtually no
boilerplate. Designed to simplify cloud infrastructure without
sacrificing flexibility, the framework lets you declaratively specify
tasks, IAM roles, log groups, secrets, and networking in a concise
YAML configuration.

By automating the orchestration of ALBs, security groups, EFS mounts,
CloudWatch logs, and scheduled or daemon tasks, B<App::FargateStack>
reduces the friction of getting secure, production-grade workloads
running in AWS. You supply a config file, and the tool intelligently
discovers or provisions required resources.

It supports common service types such as HTTP, HTTPS, daemon, and cron
tasks, and handles resource scoping, role-based access, and health
checks behind the scenes.  It assumes a reasonable AWS account layout
and defaults, but gives you escape hatches where needed.

B<App::FargateStack> is ideal for developers who want the power of ECS
and Fargate without diving into the deep end of Terraform,
CloudFormation, or the AWS Console.

=head2 Features

=over 4

=item *

Minimal configuration: launch a Fargate service with just a task name
and container image

=item *

Supports multiple task types: HTTP, HTTPS, daemon, cron (scheduled)

=item *

Automatic resource provisioning: IAM roles, log groups, target groups,
listeners, etc.

=item *

Discovers and reuses existing AWS resources when available (e.g.,
VPCs, subnets, ALBs)

=item *

Secret injection from AWS Secrets Manager

=item *

CloudWatch log integration with configurable retention

=item *

Optional EFS volume support (per-task configuration)

=item *

Public or private service deployment (via ALB in public subnet or
internal-only)

=item *

Built-in service health check integration

=item *

Automatic IAM role and policy generation based on task needs

=item *

Optional HTTPS support with ACM certificate discovery and creation

=item *

Lightweight dependency stack: Perl, AWS CLI, a few CPAN modules

=item *

Convenient CLI: start, stop, update, and tail logs for any service

=back

=head1 USAGE

=head2 Commands

 Command         Arguments            Description
 -------         ---------            -----------
 apply                                reads config and creates resources
 create-service  task-name            create a new service (see Note 4)
 delete-service  task-name            delete an existing service
 help            {subject}            displays general help or help on a particular subject (see Note 2)
 list-tasks                           list running tasks
 list-zones      domain               list the hosted zones for a domain
 logs           task-name start end   display CloudWatch logs (see Note 5)
 plan                                 reads config and reports on resource creation
 register        task-name            register a task name
 run-task        task-name            launches an adhoc task
 start-service   task-name [count]    starts a service
 status          task-name            provides status of a task and event listing
 stop-service    task-name            stops a running service
 update-policy                        updates the ECS policy in the event of resource changes
 update-target   task-name            force update of target definition
 version                              display the current version number

=head2 Options

 -h, --help                 help
     --cache, --no-cache    use the configuration file as the source of truth (see Note 8)
 -c, --config               path to the .yml configuration
 -C, --create-alb           forces creation of a new ALB, prevents use of an existing ALB
 -d, --dryrun               just report actions, do not apply
 --color, --no-color        default: color
 --log-level                'trace', 'debug', 'info', 'warn', 'error', default: info (See Note 6)
 --log-time, --no-log-time  for logs command, output CloudWatch timestamp (default: --no-log-time)
 --log-wait, --no-log-wait  for logs command, continue to monitor logs (default: --log-wait)
 -p, --profile              AWS profile (see Note 1)
     --route53-profile      set this if your Route 53 zones are in a different account (See Note 10)
 -s, --skip-register        skips registering a new task definition when using update-target (See Note 7)
 -u, --update, --no-update  update config (See Note 9)
 -U, --unlink, --no-unlink  delete or keep temp files (default: --unlink)
 -w, --wait, --no-wait      wait for tasks to complete and then dump the log (applies to adhoc tasks)
 -v, --version              script version

=head2 Notes

=over 4

=item (1) Use the --profile option to override the profile defined in
the configuration file.

The Route 53 service uses the same profile unless you specify a profile
name in the C<route53> section of the configuration file.

=item (2) You can get help using the C<--help> option or use the help
command with a subject.

 app-FargateStack help overview

If you do not provide a subject then you will get the same information
as C<--help>. Use C<help list> to get a list of available subjects.

=item (3) You must log at least at the 'info' level to report progress.

=item (4) By default an ECS service is NOT created for you by default
for daemon and http tasks.

=item (5) You can tail or display a set of log events from a task's
log stream:

 app-Fargate logs [--log-wait] [--log-time] start end

=over 8

=item --log-wait --no-log-wait (optional)

Continue to monitor stream and dump logs to STDOUT

default: --log-wait

=item --log-time, --no-log-time (optional)

Output the CloudWatch timestamp of the message.

default: --log-time

=item task-name

The name of the task whose logs you want to view.

=item start

Starting date and optionally time of the log events to display. Format can be one
of:

 Nd => N days ago
 Nm => N minutes ago
 Nh => N hours ago

 mm/dd/yyyy
 mm/dd/yyyy hh:mm::ss

=item end

If provided both start and end must date-time strings.

=back

=item (6) The default log level is 'info' which will create an audit
trail of resource provisioning. Certain commands log at the 'error'
level to reduce console noise. Logging at lower levels will prevent
potential useful messages from being displayed. To see the AWS CLI
commands being executed, log at the 'debug' level. The 'trace' level
will output the result of the AWS CLI commands.

=item (7) Use C<--skip-register> if you want to update a tasks target
rule without registering a new task definition. This is typically done
if for some reason your target rule is out of sync with your task
definition version.

=item (8) To speed up processing and avoid unnecessary API calls the
framework considers the configuration file the source of truth and a
reliable representation of the state of the stack. If you want to
re-sync the configuration file set C<--no-cache> and run C<plan>. In
most cases this should not be necessary as the framework will
invalidate the configuration if an error occurs forcing a re-sync on
the next run of C<plan> or C<apply>.

=item (9) C<--no-update> is not permitted with C<apply>. If you need a
dry plan without applying or updating the config, use C<--dryrun> (and
optionally C<--no-update>) with C<plan>.

=item (10) Set C<--route53-profile> to the profile that has
permissions to manage your hosted zones. By default the script will
use the default profile.

=back

=head1 OVERVIEW

I<NOTE: This is a brief overview of C<App::FargateStack>. To see a 
list of topics providing more detail use the C<help list> command.>

The C<App::FargateStack> framework, as its name implies provide developers
with a tool to create Fargate tasks and services. It has been designed
to make creating and launching Fargate based services as simple as
possible. Accordingly, it provides logical and pragmatic defaults
based on the common uses for Fargate based applications. You can
however customize many of the resources being built by the
script.

Using a YAML based configuration file, you specify the your required
resources and their attributes, run the C<app-FargateStack> script and
launch your application.

Using this framework you can:

=over 4

=item * ...build internal or external facing HTTP services that:

=over 8

=item * ...automatically provision certificates for external facing web applications

=item * ...use an existing or create a new internal or external facing application load balancer (ALB).

=item * ...automatically create an alias record in Route 53 for your domain

=item * ...create a listener rule to redirect port 80 requests to 443 

=back

=item * ...create queues and buckets to support your application

=item * ...use a dryrun mode to report the resources that will be built
before building them

=item * ...run C<app-FargateStack> multiple times (idempotency)

=item * ...create daemon services

=item * ...create scheduled jobs

=item * ...execute adhoc jobs

=back

=head2 Additional Features

=over 4

=item - inject secrets into the container's environment using a simple
syntax (See L</INJECTING SECRETS FROM SECRETS MANAGER>)

=item - detection and re-use of existing resources like EFS files systems, load balancers, buckets and queues

=item - automatic IAM role and policy generation based on configured resources

=item - define and launch multiple independent Fargate tasks and services under a single stack

=item - automatic creation of log groups with customizable retention period

=item - discovery of existing environment to intelligently populate configuration defaults

=back

=head2 Minimal Configuration

Getting a Fargate task up and running requires that you provision and
configure multiple AWS resources. Stitching it together using
B<Terraform> or B<CloudFormation> can be tedious and time consuming,
even if you know what resources to provision AND how to stitch it
together.

The motivation behind writing this framework was to take the drudgery
of writing declarative resource generators for all of the resources required
to run a simple task, create basic web applications or RESTful
APIs. Instead, we wanted a framework that covered 90% of our use cases
while allowing our development workflow to go something like:

=over 4

=item Create a Docker image that implements our worker, web app or API

=item Create a minimal configuration file that describes our application

=item Execute the framework's script and create the necessary AWS infrastructure

=item Launch the http server, daemon, scheduled job, or adhoc worker

=back

Of course, this is only a "good idea" if second point is truly
minimal, otherwise it becomes an exercise similar to using Terraform
or CloudFormation. So what is the minimum amount of configuration to
inform our framework so it can create our Fargate worker? How's this
for minimal?

 ---
 app:
   name: my-stack
 tasks:
   my-worker:
     type: task
     image: my-worker:latest
     schedule: cron(50 12 * * * *)

Using this minimal configuration and running C<app-FargateStack> like this:

 app-FargateStack plan

...the framework would create the following resources in your VPC:

=over 8

=item * a cluster name C<my-stack-cluster>

=item * a security group for the cluster

=item * an IAM role for the the cluster

=item * an IAM  policy that has permissions enabling your worker

=item * an ECS task definition for your work with defaults

=item * a CloudWatch log group

=item * an EventBridge target event

=item * an IAM role for EventBridge

=item * an IAM policy for EventBridge

=item * an EventBridge rule that schedules the worker

=back

...so as you can see this can be a daunting task which becomes even
more annoying when you want your worker to be able to access other AWS
resources like buckets, queues or EFS directories.

=head2 Web Applications

Creating a web application using a minimal configuration works too. To
build a web application you can start with this minimal configuration:

 ---
 app:
   name: my-web-app
 domain: my-web-app.example.com
 route53:
   zone_id: Z3YYX2RBQJTYM
 tasks:
   apache:
     type: https
     image: my-web-app:latest

This will create an externally facing web application for you with
these resources:

=over 4

=item *  A certificate for your domain

=item * A Fargate cluster

=item * IAM roles and policies

=item * A listener and listener rules

=item * A CloudWatch log group

=item * Security groups

=item * A target group

=item * A task definition

=item * An ALB if one is not detected

=back

Once again, launching a Fargate service requires a
lot of fiddling with AWS resources! Getting all of the plumbing
installed and working requires a lot of what and how knowledge.

=head2 Adding or Changing Resources

Adding or updating resources for an existing application should also be
easy. Updating the infrastructure should just be a matter of updating
the configuration and re-running the framework's script. When you
update the configuration the script will detect changes and update the
necessary resources.

Currently the framework supports adding a single SQS queue, a single
S3 bucket, volumes using EFS mount points and, environment variables
that can be injected from AWS Secrets Manager.

 my-worker:
   image: my-worker:latest
   command: /usr/local/bin/my-worker.pl
   type: task
   schedule: cron(00 15 * * * *)   
   bucket:
     name: my-worker-bucket
   queue:
     name: my-worker-queue
   environment:
     ENVIRONMENT=prod
   secrets:
     db_password:DB_PASSWORD
   efs:
     id: fs-abcde12355
     path: /
     mount_point: /mnt/my-worker

Adding new resources would normally require you to update your
policies to allow your worker to access these resource. However, the
framework automatically detects that the policy needs to be updated
when new resources are added (even secrets) and takes care of that for
you.

See C<app-Fargate help configuration> for more information about
resources and options.

=head2 Configuration as State

The framework attempts to be as transparent as possible regarding what
it is doing, how long it takes, what the result was and most
importantly I<what defaults were used during resource
provisioning>. Every time the framework is run, the configuration file
is updated based on any new resources provisioned or configured.  For
example, if you did not specify subnets, they are inferred by
inspecting your VPC and automatically added to the configuration file.

This gives you a single view into your Fargate application

=head1 COMMAND LIST

The basic syntax of the framework's CLI is:

 app-FargateStack command --config fargate-stack.yml [options] command-args

You must provide at least a command.

=head2 Configuration File Naming

Your configuration file can be named anything, but by convention your
configuration file should have a F<.yml> extension. If you don't
provide a configuration filename the default configuration file
F<fargate-stack.yml> will be used. You can also set the
C<FARGATE_STACK_CONFIG> environment variable to the name of your
configuration file.

=head2 Command Logging

=over 4

=item Commands will generally produce log output at the default level
(C<info>). You can see what AWS commands are being executed using the
C<debug> level. If you'd like see the results of the AWS CLI commands use the
C<trace> level.

=item Commands that are expected to produce informational output
(e.g. C<status>, C<logs>, C<list-tasks>, C<list-zone>, etc) will log
at the C<error> level which will eliminate log noise on the console.

=item Logs are written to STDERR.

=item The default is to colorize log
messages. Use C<--no-color> if you don't like color.

=back

=head2 Command Descriptions

=head3 help

 help [subject]

Displays basic usage or help on a particular subject. To see a list of
help subject use C<help list>. The script will attemp to do a regexp
match if you do provide the exact help topic, so you can cheat and use
shortened versions of the topic.

 help cloudwatch

=head3 apply

Reads the configuration file and determines what actions to perform
and what resources will be built.  Builds resources incrementally and
updates configuration file with resource details.

=head3 create-service

 create-service service-name

When you provision an HTTP, HTTPS or daemon service the framework
provisions all of the components for you to execute the task. It
B<does not> however, start the service. Use this command to create and
start the service.

 app-FargateTask start-service service-name

If you want to provision more than 1 task for your service add a count argument.

 app-FargateTask start-service service-name 2

=head3 delete-service

 delete-service service-name

This command will delete a service. If you just want to temporarily
stop the service use the C<stop-service> command.

=head3 list-tasks

Lists running tasks and outputs a table of information about the tasks.

 Task Name
 Task Id
 Status
 Memory
 CPU
 Start Time
 Elapsed Time

=head3 list-zones

 list-zones domain-name

This command will list the hosted zones for a specific domain. The
framework automatically detects the appropriate hosted zone for your
domain if the C<zone_id:> key is missing from your configuration when
you have an HTTP or HTTPS task defined.

Example:

 app-FargateStack list-zones --profile prod

=head3 logs

 logs start-time end-time

To view your log streams use the C<logs> command. This command will
display the logs for the most recent log stream in the log group. By
default the start time is the time of the first event.

=over 4

=item Use C<--log-wait> to continuously poll the log stream.

=item Use C<--no-log-time> if your logs already have timestamps and do
not want to see CloudWatch timestamps. This is useful when you are
logging time in your time zone and do not want to be confused seeing
times that don't line up.

=item C<start-time> can be a "Nh", "Nm", "Nd" where N is an integer
and h=hours ago, m=minutes ago and d=days ago.

=item C<start-time> and C<end-time> can be "mm/dd/yyyy hh:mm:ss" or just "mm/dd/yyyy"

=item C<end-time> must always be a date-time string.

=back

=head3 plan              

Reads the configuration file and determines what actions to perform
and what resources will be built. Only updates configuration file with
resource details but DOES NOT build them.

=head3 register

 register task-name

Forces registration of a new task definition.

=head3 run-task

 run-task task-name

Launches a one-shot Fargate task. The default is to wait for the task
to complete and output the task's log to STDERR.  To launch the task
and exit use the C<--no-wait> option.

=head3 status

 status service-name

Displays the status of a service and the most recent event message in
tabular form.

=head3 stop-task

 stop-task task-arn|task-id

Stops a running task. To get the task id, use the C<list-tasks> command.

=head3 stop-service

 stop-service service-name

Stops a running service by setting its desire count to 0.

=head3 start-service

 start-service service-name [count]

Start a service. C<count> is the desired count of tasks. The default count is 1.

=head3 update-policy

 update-policy

Forces the framework to re-evaluate resources and align the
policy. Will not apply changes in C<--dryrun> mode. Under normal
circumstances you should not need to run this command, however if you
find that your Fargate policy lacks permissions for resources you have
configure, this will make sure that all configured resources are
included in your policy.

If C<update-policy> identifies a need to update your role policy, you
can view the changes before they are applied by running the C<plan> command at the C<trace> log level.

 app-Fargate --log-level trace plan

=head3 update-target

 update-target task-name

Updates an EventBridge rule and rule target. For tasks of type "task"
(typically scheduled jobs) when you change the schedule the rule must
be deleted, re-created and associated with the target task. This
command will detect the drift in your configuration and apply the
changes if not in C<--dryrun> mode.

=head3 version              

Outputs the current version of C<App::FargateStack>.

=head1 CLOUDWATCH LOG GROUPS

A CloudWatch log group is automatically provisioned for each
application stack. By default, the log group name is
/ecs/<application-name>, and log streams are created per task.

For example, given the following configuration:

 app:
   name: my-stack
 ...
 tasks:
   apache:
     type: https

The framework will:

=over 4

=item * ...create a log group named /ecs/my-stack

=item * ...configure the apache task to write log streams with a prefix
like my-stack/apache/*

=back

By default, the log group is set to retain logs for 14 days if
C<retention_days> is not specified. You can override this by
specifying a custom retention period using the C<retention_days> key
in the task's log_group section:

 log_group:
   retention_days: 30

=head2 Notes

=over 4

=item * The log group is reused if it already exists.

=item * Only numeric values accepted by CloudWatch are valid for
retention_days (e.g., 1, 3, 5, 7, 14, 30, 60, 90, etc.).

=item * You can customize the log group name by setting the name in the C<log_group:> section.

 log_group:
   retention_days: 14
   name: /ecs/my-stack

=back

=head1 IAM PERMISSIONS

This framework uses a single IAM role for all tasks defined within an
application stack.  The assumption is that services within the stack
share a trust boundary and operate on shared infrastructure.  This
simplifies IAM management while maintaining strict isolation between
stacks.

IAM roles and policies are automatically created based on your
configuration.  Only the minimum required permissions are granted.
For example, if your configuration defines an S3 bucket, the ECS task
role will be permitted to access only that specific bucket - not all
buckets in your account. The policy is updated when new resources are
added to the configuration file.

The role name an role policy name are found under the C<role:> key in
the configuration. A role name and role policy name are automatically
fabricated for you from the name you specified under the C<app:> key.

=head1 SECURITY GROUPS

A security group is automatically provisioned for your Fargate
cluster.  If you define a task of type C<http> or C<https>, the
security group attached to your Application Load Balancer (ALB) is
automatically authorized for ingress to your Fargate task. This is a
rule allowing ALB-to-Fargate traffic.

=head1 FILESYSTEM SUPPORT

EFS volumes are defined per task and mounted according to the task
definition. This design provides fine-grained control over EFS usage,
rather than treating it as a global, stack-level resource.

Each task that requires EFS support must include both a volume and
mountPoint configuration. The ECS task role is automatically updated
to allow EFS access based on your specification.

To specify EFS support in a task:

 efs:
   id: fs-1234567b
   mount_point: /mnt/my-stack
   path: /
   readonly:

Acceptable values for C<readonly> are "true" and "false".

=head2 Field Descriptions

=over 4

=item id:

The ID of an existing EFS filesystem. The framework does not provision
the EFS, but will validate its existence in the current AWS account
and region.

=item mount_point:

The container path to which the EFS volume will be mounted.

=item path:

The path on the EFS filesystem to map to your container's mount point.

=item readonly:

Optional. Set to C<true> to mount the EFS as read-only. Defaults to
C<false>.

=back

=head2 Additional Notes

=over 4

=item * The ECS role's policy for your task is automatically modified
to allow read/write EFS access. Set C<readonly:> in your task's
C<efs:> section to "true" if only want read support.

=item * Your EFS security group must allow access from private subnets
where the Fargate tasks are placed.

=item * No changes are made to the EFS security group; the framework
assumes access is already configured

=item * Only one EFS volume is currently supported per task configuration.

=item * EFS volumes are task-scoped and reused only where explicitly configured.

=item * The framework does not automatically provision an EFS
filesystem for you. The framework does however validate that the
filesystem exists in the current account and region.

=back

=head1 CONFIGURATION

The C<App::FargateStack> framework defines your application stack
using a YAML configuration file. This file describes your
application's services, their resource needs, and how they should be
deployed. Then configuration is updated whenever your run C<plan> or
C<apply>.

=head2 GETTING STARTED

Start by creating a minimal YAML configuration file with the required sections:

  app:
    name: my-stack

  tasks:
    my-stack-daemon-1:
      image: my-stack-daemon:latest
      type: daemon

Each task represents a containerized service that you want to run. In this example,
the framework will provision:

=over 4

=item * a Fargate cluster in the C<us-east-1> region

=item * one daemon service

=item * networking in the default VPC using a private subnet

=item * any required AWS resources using the default profile (or the one specified in C<AWS_PROFILE>)

=back

Once configured, run:

  app-FargateStack plan

This will analyze your configuration and report what will be created. It will also
update the file with any discovered defaults. To apply the plan and provision the
stack, run:

  app-FargateStack -c my-stack.yml apply

B<You do not need to specify every setting up front. The framework will attempt to
auto-discover certain AWS resources if they are not configured.>

=head2 VPC AND SUBNET DISCOVERY

If you do not specify a C<vpc_id> in your configuration, the framework will attempt
to locate a usable VPC automatically.

A VPC is considered usable if it meets the following criteria:

=over 4

=item * It is attached to an Internet Gateway (IGW)

=item * It has at least one available NAT Gateway

=back

If no eligible VPCs are found, the process will fail with an error. If multiple
eligible VPCs are found, the framework will abort and list the candidate VPC IDs.
You must then explicitly set the C<vpc_id:> in your configuration to resolve
the ambiguity.

If exactly one eligible VPC is found, it will be used automatically,
and a warning will be logged to indicate that the selection was
inferred.

=head2 SUBNET SELECTION

If no subnets are specified in the configuration, the framework will query all
subnets in the selected VPC and categorize them as either public or private.

The task will be placed in a private subnet by default. For this to succeed,
your VPC must have at least one private subnet with a route to a NAT Gateway,
or have appropriate VPC endpoints configured for ECR, S3, STS, CloudWatch Logs,
and any other services your task needs.

If subnets are explicitly specified in your configuration, the
framework will validate them and warn if they are not reachable or are
not usable for Fargate tasks.

=head2 REQUIRED SECTIONS

At minimum, your configuration must include the following:

  app:
    name: my-stack

  tasks:
    my-task:
      image: my-image
      type: daemon | task | http | https

For task types C<http> or C<https>, you must also specify a domain name:

  domain: example.com

=head2 FULL SCHEMA OVERVIEW

The framework will expand and update your configuration file with default values as needed.
Here is the full schema outline. All keys are optional unless otherwise noted:

  ---
  account:
  alb:
    arn:
    name:
    port:
    type:
  app:
    name:             # required
    version:
  certificate_arn:
  cluster:
    arn:
    name:
  default_log_group:
  domain:              # required for http/https tasks
  id:
  last_updated:
  region:
  role:
    arn:
    name:
    policy_name:
  route53:
    profile:
    zone_id:
  security_groups:
    alb:
      group_id:
      group_name:
    fargate:
      group_id:
      group_name:
  subnets:
    private:
    public:
  tasks:
    my-task:
      arn:
      cpu:
      family:
      image:           # required
      log_group:
        arn:
        name:
        retention_days:
      memory:
      name:
      target_group_arn:
      target_group_name:
      task_definition_arn:
      type:            # required (daemon, task, http, https)
  vpc_id:

=cut



=head1 ENVIRONMENT VARIABLES

The Fargate stack framework allows you to define environment variables for each
task. These variables are included in the ECS task definition and made available
to your container at runtime.

Environment variables are specified under the C<environment:> key within the task
configuration.

=head2 BASIC USAGE

  task:
    apache:
      environment:
        ENVIRONMENT: prod
        LOG_LEVEL: info
        DEBUG_MODE: 0

Each key/value pair will be passed to the container as an environment
variable.

Environment variable values are treated literally; shell-style
expressions such as ${VAR} are not interpolated. If you need dynamic
values, populate them explicitly in the configuration or use the
C<secrets:> block for sensitive data.

This mechanism is ideal for non-sensitive configuration such as
runtime flags, environment names, or log levels.

=head2 SECURITY NOTE

Avoid placing secrets (such as passwords, tokens, or private keys) directly in the
C<environment:> section. That mechanism is intended for non-sensitive configuration
data.

To securely inject secrets into the task environment, use the C<secrets:> section
of your task configuration. This integrates with AWS Secrets Manager and ensures
secrets are passed securely to your container.

=head2 INJECTING SECRETS FROM SECRETS MANAGER

To inject secrets into your ECS task from AWS Secrets Manager, define a C<secrets:>
block in the task configuration. Each entry in this list maps a Secrets Manager
secret path to an environment variable name using the following format:

  /secret/path:ENV_VAR_NAME

Example:

  task:
    apache:
      secrets:
        - /my-stack/mysql-password:DB_PASSWORD

This configuration retrieves the secret value from C</my-stack/mysql-password>
and injects it into the container environment as C<DB_PASSWORD>.

Secrets are referenced via their ARN using ECS's native secrets mechanism,
which securely injects them without placing plaintext values in the task definition.

=head2 BEST PRACTICES

Avoid placing secrets in the C<environment:> block. That block is for non-sensitive
configuration values and exposes data in plaintext.

Use clear, descriptive environment variable names (e.g., C<DB_PASSWORD>, C<API_KEY>)
and organize your Secrets Manager paths consistently with your stack naming.

=head1 SQS QUEUES

The Fargate stack framework supports configuring and provisioning a
single AWS SQS queue, including an optional dead letter queue (DLQs).

A queue is defined at the stack level and is accessible to all tasks
and services within the same stack. IAM permissions are automatically
scoped to include only the explicitly configured queue and its
associated DLQ (if any).

I<Only one queue and one optional DLQ may be configured per stack.>

=head2 BASIC CONFIGURATION

At minimum, a queue requires a name:

  queue:
    name: fu-man-q

If you define C<max_receive_count> in the queue configuration, a DLQ
will be created automatically. You can optionally override its name
and attributes using the top-level C<dlq> key:

  queue:
    name: fu-man-q
    max_receive_count: 5

  dlq:
    name: custom-dlq-name

If you do not specify a C<dlq.name>, the framework defaults to appending C<-dlq> to
the main queue name (e.g., C<fu-man-q-dlq>).

=head2 DEFAULT QUEUE ATTRIBUTES

If not specified, the framework applies default values to match AWS's standard SQS behavior:

  queue:
    name: fu-man-q
    visibility_timeout: 30
    delay_seconds: 0
    receive_message_wait_time_seconds: 0
    message_retention_period: 345600
    maximum_message_size: 262144
    max_receive_count: 5  # triggers DLQ creation

  dlq:
    visibility_timeout: 30
    delay_seconds: 0
    receive_message_wait_time_seconds: 0
    message_retention_period: 345600
    maximum_message_size: 262144

=head2 DLQ DESIGN NOTE

A dead letter queue is not a special type - it is simply another queue used
to receive messages that have been unsuccessfully processed. It is modeled
as a standalone queue and defined at the top level of the stack configuration.

The C<dlq> block is defined at the same level as C<queue>, not nested within it.
If no overrides are provided, DLQ attributes default to AWS attribute defaults.

=head2 IAM POLICY UPDATES

Adding a new queue to an existing stack will not only create the queue, but
also update the IAM policy associated with your stack to include permissions
for the newly defined queue and DLQ (if applicable).

=head1 SCHEDULED JOBS

The Fargate stack framework allows you to schedule container-based jobs
using AWS EventBridge. This is useful for recurring tasks like report generation,
batch processing, database maintenance, and other periodic workflows.

A scheduled job is defined like any other task, using C<type: task>, and
adding a C<schedule:> key in AWS EventBridge cron format.

=head2 SCHEDULING A JOB

To schedule a job, add a C<schedule:> key to your task definition. The
value must be a valid AWS cron expression, such as:

  cron(0 2 * * ? *)   # every day at 2:00 AM UTC

Example:

  tasks:
    daily-report:
      type: task
      image: report-runner:latest
      schedule: cron(0 2 * * ? *)

I<Note: All cron expressions are interpreted in UTC.>

The framework will automatically create an EventBridge rule tied to
the task definition. When triggered, it will launch a one-off Fargate
task based on the configuration. The EventBridge rule is named using
the pattern "<task>-schedule".

All scheduled tasks support environment variables, secrets, and other
standard task features.

=head2 RUNNING AN ADHOC JOB

You can run a scheduled (or unscheduled) task manually at any time using:

  app-FargateStack run-task task-name

By default, this will:

=over 4

=item * Launch the task using the defined image and configuration

=item * Wait for the task to complete (unless C<--no-wait> is passed)

=item * Retrieve and print the logs from CloudWatch when the task exits

=back

This is ideal for debugging, re-running failed jobs, or triggering
occasional maintenance tasks on demand.

=head2 SERVICES VS TASKS

A task of type C<daemon> is launched as a long-running ECS service
and benefits from restart policies and availability guarantees.

A task of type C<task> is run using C<run-task> and may run once,
forever, or periodically - but it will not be automatically restarted
if it fails.

=head1 S3 BUCKET ACCESS

The Fargate stack framework supports creating a new S3 bucket or
using an existing one. The bucket can be used by your ECS tasks
and services, and the framework will configure the necessary IAM
permissions for access.

By default, full read/write access is granted unless you specify
restrictions (e.g., read-only or path-level constraints). In this model,
no bucket policy is required or modified.

I<Note: Full access includes s3:GetObject, s3:PutObject, s3:DeleteObject, and
s3:ListBucket.  Readonly access is limited to s3:GetObject and
s3:ListBucket.>

=head2 BASIC CONFIGURATION

You define a bucket in your configuration like this:

  bucket:
    name: my-app-bucket

By default, this grants full read/write access to the entire bucket via the
IAM role attached to your ECS task definition.

=head2 RESTRICTED ACCESS

You can limit access to a subset of the bucket using the C<readonly:> and
C<paths:> keys:

  bucket:
    name: my-app-bucket
    readonly: true
    paths:
      - public/*
      - logs/*

This will:

=over 4

=item * Grant only C<s3:GetObject> and C<s3:ListBucket> permissions

=item * Limit access to the specified path prefixes

=back

The C<paths:> values are interpreted as S3 key prefixes and inserted
directly into the role policy.

If you specify C<readonly: true> but omit C<paths:>, read-only access will
apply to the entire bucket. If you omit both keys, full read/write access
is granted.

=head2 IAM-BASED ENFORCEMENT

Bucket access is enforced exclusively through IAM role permissions. The
framework does not modify or require an S3 bucket policy. This keeps your
configuration simpler and avoids potential conflicts with externally
managed bucket policies.

=head2 USING EXISTING BUCKETS

If you reference an existing bucket not created by the framework, be aware
that the bucket's own policy may still restrict access.

In particular:

=over 4

=item * The IAM role created by the framework may permit access to a path

=item * But a bucket policy with an explicit C<Deny> will override that and block access

=item * This restriction will only be discovered at runtime when your task attempts access

=back

To avoid surprises, ensure that any bucket policy on an external bucket
permits access from the IAM role you're configuring.

=head1 HTTP SERVICES

=head2 Overview

To create a Fargate HTTP service set the C<type:> key in your task's
configuration section to "http" or "https".

The task type ("http" or "https") determines:

=over 4 

=item *  the B<type of load balancer> that will be used or created

=item * whether or not a B<certificate will be used or created>

=item * what B<default port> will be configured in your ALB's listener
rule

=back

=head2 Key Assumptions When Creating HTTP Services

=over 4

=item * Your domain is managed in Route 53 and your profile can create
Route 53 record sets.

I<Note: If your domain is managed in a different AWS account, set a
separate C<profile:> value in the C<route53:> section of the
configuration file.  Your profile should have sufficient permissions
to manage Route 53 recordsets.>

=item * Your Fargate task will be deployed in a private subnet and
will listen on port 80.

=item * No certificate will be provisioned for internal facing
applications. Traffic by default to internal facing applications
(those that use an internal ALB) will be insecure. I<This may become
an option in the future.>

=back

=head2 Architecture

When you set your task type to "http" or "https" a default
architecture depicted below will be provisioned.

                            (optional)
                        +------------------+
                        |  Internet Client |
                        +--------+---------+
                                 |
                      [only if ALB is external]
                                 |
                    +------------v--------------+
                    |  Route 53 Hosted Zone     |
                    |  Alias: myapp.example.com |
                    |     --> ALB DNS Name      |
                    +----------+----------------+
                                 |
                      +----------v----------+
                      | Application Load    |
                      | Balancer (ALB)      |
                      | [internal or        |
                      |  internet-facing]   |
                      |                     |
                      | Listeners:          |
                      |   - Port 80         |
                      |   - Port 443 w/ TLS |
                      |     + ACM Cert      |
                      |       (TLS/SSL)     |
                      |     [if external]   |
                      +----------+----------+
                                 |
                          +------v-------+
                          | Target Group |
                          +------+-------+
                                 |
                         +-------v---------+
                         | ECS Service     |
                         | (Fargate Task)  |
                         +-------+---------+
                                 |
                       +---------v----------+
                       | VPC Private Subnet |
                       +--------------------+

This default architecture provides a repeatable, production-ready
deployment pattern for HTTP services with minimal configuration.

=head2 Behavior by Task Type

For HTTP services, you set the task type to either "http" or "https"
(these are the only options that will trigger a task to be configured
for HTTP services). The table below summarizes the configurations by
task type.

 +-------+----------+-------------+-----------+---------------+
 | Type  | ALB type | Certificate |    Port   |  Hosted Zone  |
 +-------+----------+-------------+-----------+---------------+
 | http  | internal |    No       |    80     |   private     |
 | https | external |   Yes       |   443     |   public      |
 |       |          |             | 80 => 443 |               |
 +-------+----------+-------------+-----------+---------------+

I<NOTE: You must provide a domain name for both an internal and
external facing HTTP service. This also implies you must have a
both a B<private> and B<public> hosted zone for your domain.>

Your task type will also determine which type of subnet is required
and where to search for an existing ALB to use. If you want to prevent
re-use of an existing ALB and force the creation of a new one use the
C<--create-alb> option when you run your first plan.

In your initial configuration you do not need to specify the subnets
or the hosted zone id.  The framework will discover those and report
if any required resources are unavailable. If the task type is
"https", the script looks for a public zone, public subnets and an
internet-facing ALB otherwise it looks for a private zone, private
subnets and an internal ALB.

=head2 ACM Certificate Management

If the task type is "https" and no ACM certificate currently exists
for your domain, the framework will automatically provision one. The
certificate will be created in the same region as the ALB and issued
via AWS Certificate Manager. If the certificate is validated  via DNS
and subsequently attached to the listener on port 443.

=head2 Port and Listener Rules

For external-facing apps, a separate listener on port 80 is
created. It forwards traffic to port 443 using a default redirect rule
(301). If you do not want a redirect rule, set the C<redirect_80:> in
the C<alb:> section to "false".

If you want your internal application to listen on a port other than
80, set the C<port:> key in the C<alb:> section to a new port
value.

=head2 Example Minimal Configuration

 app:
   name: http-test
 domain: http-test.example.com
 task:
   apache:
     type: http
     image: http-test:latest

Based on this minimal configuration C<app-FargateStack> will enrich
the configuration with appropriate defaults and proceed to provision
your HTTP service.

To do that, the framework attempts to discover the resources required
for your service. If your environment is not compatible with creating
the service, the framework will report the missing resources and
abort the process.

Given this minimal configuration for an internal ("http") or
external ("https") HTTP service, discovery entails:

=over 4

=item  ...determining your VPC's ID

=item  ...identifying the private subnet IDs

=item ...determining if there is and existing load balancer with the
correct scheme

=item  ...finding your load balancer's security group (if an ALB exists)

=item  ...looking for a listener rule on port 80 (and 443 if type is
"https"), including a default forwarding redirect rule

=item  ...validating that you have a private or public hosted zone
in Route 53 that supports your domain

=item  ...setting other defaults for additional resources to be built (log
groups, cluster, target group, etc)

=item  ...determining if an ACM certificate exists for your domain
(if type is "https")

=back

I<Note: Discovery of these resources is only done when they are
missing from your configuration. If you have multiple VPCs for example
you can should explicitly set C<vpc_id:> in the configuration to
identify the target VPC.  Likewise you can explicitly set other
resource configurations (subnets, ALBs, Route 53, etc).>

Resources are provisioned and your configuration file is updated
incrementally as C<app-FargateStack> compares your environment to the
environment required for your stack. When either plan or
apply complete your configuration is updated giving you complete
insight into what resources were found and what resources will be
provisioned. See L<CONFIGURATION> for complete details on resource
configurations.>

Your environment will be validated against the criteria described
below.

=over 4

=item * You have at least 2 private subnets available for deployment

Technically you can launch a task with only 1 subnet but for services
behind an ALB Fargate requires 2 subnets.

I<When you create a service with a load balancer, you must specify
two or more subnets in different Availability Zones. - AWS Docs>

=item * You have a hosted zone for your domain of the appropriate type
(private for type "http", public for type "https")

=back

As discovery progresses, existing and required resources are logged
and your configuration file is updated. If you are B<NOT> running in
dryrun mode, resources will be created immediately as they are
discovered to be missing from your environment.

=head2 Application Load Balancer

When you provision an HTTP service, whether or not it is secure, the
service will placed behind an application load balancer. Your Fargate
service is created in private subnets, so your VPC must contain at
least two private subnets.  Your load balancer can either be
I<internally> or I<externally facing>.

By default, the framework looks for and will reuse a load balancer
with the correct scheme (internal or internet-facing), in a subnet
aligned with your task type. The ALB will be placed in public subnets
if it is internet-facing. You can override that behavior by either
explicitly setting the ALB arn in the C<alb:> section of the
configuration or pass C<--create-alb> when you run our plan and apply.

If no ALB is found or you passed the C<--create-alb> option, a new ALB
is provisioned. When creating a new ALB, C<app-FargateStack> will also
create the necessary listeners and listener rules for the ports you
have configured.

=head3 Why Does the Framework Force the Use of an Load Balancer?

While it is possible to avoid the use or the creation of a load balancer
for your service, the framework forces you to use one for at least two
reasons. Firstly, the IP address of your service may not be stable and
is not friendly for development or production purposes. The framework
is, after all trying its best to promote best practices while
preventing you from having to know how all the sausage is made.

Secondly, it is almost guaranteed that you will eventually want
a domain name for your production service - whether it is an
internally facing microservice or an externally facing web
application.

Creating an alias in Route 53 for your domain pointing to the ALB
ensures you don't need to update application configurations with the
service's dynamic IP address. Additionally, using a load balancer
allows you to create custom routing rules to your service. If you want
to run multiple tasks for your service to support handling more
traffice a load balancer is required.

With those things in mind the framework automatically uses an ALB for
HTTP services and creates an alias record (A) for your domain for both
internal and external facing services.

=head2 Roadmap for HTTP Services

=over 4

=item * path based routing on ALB listeners

=item * Auto-scaling policies

=back

=head1 CURRENT LIMITATIONS

=over 4

=item * Stacks may contain multiple daemon services, but only one task
may be exposed as an HTTP/HTTPS service via an ALB.

=item * Limited configuration options for some resources such as
advanced load balancer listener rules, custom CloudWatch metrics, or
task health check tuning.

=item * Some out of band infrastructure changes may break the ability
to re-run C<app-FargateStack> without manually updating the
configuration

=item * Support for only 1 EFS filesystem per task

=back

=head1 ROADMAP

=over 4

=item * destroy {task-name}

Destroy all resources for all tasks or for one task. Buckets and
queues will not be deleted.

=item * scaling configuration

=item * Add support for more advance configuration options for some
resources

=back

=head1 SEE ALSO

L<IPC::Run>, L<App::Command>, L<App::AWS>, L<CLI::Simple>

=head1 AUTHOR

Rob Lauer - rclauer@gmail.com

=head1 LICENSE

This script is released under the same terms as Perl itself.

=cut
